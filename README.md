# LMDeploy-Jetsonï¼šOpening a new era of Offline Embodied Intelligence

***Deploying LLMs offline on the NVIDIA Jetson platform marks the dawn of a new era in embodied intelligence, where devices can function independently without continuous internet access.***

[[ä¸­æ–‡]](./README_zh.md) | [[English]](./README.md)

This project focuses on adapting [LMDeploy](https://github.com/InternLM/lmdeploy) for use with NVIDIA Jetson series edge computing cards, facilitating the implementation of [InternLM](https://github.com/InternLM/InternLM) series LLMs for **Offline Embodied Intelligence (OEI)**.

Demoï¼š[[Bilibili]](https://www.bilibili.com/video/BV1iC411x76Q/)

## Latest NewsğŸ‰

* [2024/2/25] Updated support for [LMDeploy-v0.2.4](https://github.com/InternLM/lmdeploy/releases/tag/v0.2.4).

## Verified model/platform

* âœ…ï¼šVerified and runnable
* âŒï¼šVerified but not runnable
* â­•ï¸ï¼šPending verification

|Models|InternLM-7B|InternLM-20B|InternLM2-1.8B|InternLM2-7B|InternLM2-20B|
|:-:|:-:|:-:|:-:|:-:|:-:|
|Orin NX(16G)<br>Jetpack 5.1|âœ…<br>Mem:8.6G/16G<br>*7.39 token/s*|âœ…<br>Mem:14.7G/16G<br>*3.08 token/s*|âœ…<br>Mem:5.6G/16G<br>*22.96 token/s*|âœ…<br>Mem:9.2G/16G<br>*7.48 token/s*|âœ…<br>Mem:14.8G/16G<br>*3.19 token/s*|
|Xavier NX(8G)<br>Jetpack 5.1|âŒ|âŒ|âœ…<br>Mem:4.35G/8G<br>*28.36 token/s*|âŒ|âŒ|


**If you have more Jetson series boards, feel free to run benchmarks and submit the results via `Pull Requests` (PR) to become one of the community contributors!**

> Command of Benchmark Test: ```python profile_generation.py ../../models/internlm2-chat-1_8b-turbomind --concurrency 1 --prompt-tokens 128 --completion-tokens 128``` \
> Ref: [lmdeploy/benchmark](https://github.com/InternLM/lmdeploy/blob/main/benchmark/README.md)

## Future Work
* Testing on more Jetson boards such as Nano and AGX.
* â€¦â€¦

## Tutorial
[S1.Quantize on server by W4A16](./en/s1.md)

[S2.Install Miniconda on Jetson](./en/s2.md)

[S3.Install CMake-3.29.0 on Jetson](./en/s3.md)

[S4.Install RapidJson on Jetson](./en/s4.md)

[S5.Install Pytorch-2.1.0 on Jetson](./en/s5.md)

[S6.Port LMDeploy-0.2.4 to Jetson](./en/s6.md)

[S7.Run InternLM offline on Jetson](./en/s7.md)


## Citation

If this project is helpful to your work, please cite it using the following format:

```bibtex
@misc{hongjun2024lmdeployjetson,
    title={LMDeploy-Jetsonï¼šOpening a new era of Offline Embodied Intelligence},
    author={Hongjun An},
    url={https://github.com/BestAnHongjun/LMDeploy-Jetson},
    year={2024}
}
```

## Acknowledgements

* The [InternLM Practical Camp](https://github.com/InternLM/tutorial/) organized by the [Shanghai Artificial Intelligence Laboratory](https://www.shlab.org.cn/) has provided valuable learning materials and computational resources for my study of LLM-related theories and technologies. Teachers have also provided tremendous assistance to me. I hereby express my sincere gratitude to all of them!

## Institution

**Hongjun An**, Ph.D. Student, School of Artificial Intelligence, Optics and ElectroNics (iOPEN)
> Email: an.hongjun@foxmail.com \
> Page: www.anhongjun.top

<div align="center">
<img src="./attach/logo.jpg" width="500px">
</div>