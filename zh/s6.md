# S6.Jetson端移植LMDeploy-2.3.0

下载lmdeploy-v0.2.3：

```sh
cd ~/
git clone https://github.com/InternLM/lmdeploy.git
cd lmdeploy 
git checkout 2831dc2 # 确保为0.2.3版本
```

进入conda环境：

```sh
conda activate lmdeploy
```

安装编译依赖项：

```sh
cd ~/lmdeploy
pip install -r requirements/build.txt
```

在`~/lmdeploy`下新建`generate_jetson.sh`，填入以下内容：

```sh
#!/bin/sh

builder="-G Ninja"

if [ "$1" == "make" ]; then
    builder=""
fi

cmake ${builder} .. \
    -DCMAKE_BUILD_TYPE=RelWithDebInfo \
    -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \
    -DCMAKE_INSTALL_PREFIX=./install \
    -DBUILD_PY_FFI=ON \
    -DBUILD_MULTI_GPU=OFF \
    -DCMAKE_CUDA_FLAGS="-lineinfo" \
    -DUSE_NVTX=ON

```

赋予权限。

```sh
chmod +x generate_jetson.sh
```

新建编译文件夹：

```sh
cd ~/lmdeploy
mkdir build && cd build
```

编译LMDeploy：

```sh
../generate_jetson.sh
ninja install
```

使用vim修改`requirements/runtime.txt`，将`torch<=2.1.2,>=2.0.0`和`triton>=2.1.0,<2.2.0`两行行删除。

**提示**：为了简化依赖，我们去除了`triton`，这也同时意味着使用lmdeploy部署模型时，只能通过turbomind方式调用，而不能通过api方式。

本地安装lmdeploy-v0.2.3

```sh
cd ~/lmdeploy
pip install -e .[serve]
```